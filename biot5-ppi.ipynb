{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jl254/miniconda3/envs/kgllm/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading tokenizer_config.json: 100%|██████████| 534k/534k [00:00<00:00, 25.4MB/s]\n",
      "Downloading spiece.model: 100%|██████████| 792k/792k [00:00<00:00, 34.2MB/s]\n",
      "Downloading added_tokens.json: 100%|██████████| 61.0k/61.0k [00:00<00:00, 30.8MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 2.38k/2.38k [00:00<00:00, 841kB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 2.97M/2.97M [00:00<00:00, 32.1MB/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Downloading config.json: 100%|██████████| 792/792 [00:00<00:00, 483kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 1.01G/1.01G [00:29<00:00, 34.7MB/s]\n",
      "Downloading generation_config.json: 100%|██████████| 142/142 [00:00<00:00, 75.7kB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "def add_prefix_to_amino_acids(protein_sequence):\n",
    "    amino_acids = list(protein_sequence)\n",
    "    prefixed_amino_acids = ['<p>' + aa for aa in amino_acids]\n",
    "    new_sequence = ''.join(prefixed_amino_acids)\n",
    "    return new_sequence\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"QizhiPei/biot5-base-dti-human\", model_max_length=512, cache_dir='/data/pj20')\n",
    "model = T5ForConditionalGeneration.from_pretrained('QizhiPei/biot5-base-dti-human')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.\n"
     ]
    }
   ],
   "source": [
    "task_definition = 'Definition: Drug target interaction prediction task (a binary classification task) for the human dataset. If the given molecule and protein can interact with each other, indicate via \"Yes\". Otherwise, response via \"No\".\\n\\n'\n",
    "selfies_input = '[C][/C][=C][Branch1][C][\\\\C][C][=Branch1][C][=O][O]'\n",
    "protein_input = 'MQALRVSQALIRSFSSTARNRFQNRVREKQKLFQEDNDIPLYLKGGIVDNILYRVTMTLCLGGTVYSLYSLGWASFPRN'\n",
    "protein_input = add_prefix_to_amino_acids(protein_input)\n",
    "task_input = f'Now complete the following example -\\nInput: Molecule: <bom>{selfies_input}<eom>\\nProtein: <bop>{protein_input}<eop>\\nOutput: '\n",
    "\n",
    "model_input = task_definition + task_input\n",
    "input_ids = tokenizer(model_input, return_tensors=\"pt\").input_ids\n",
    "\n",
    "generation_config = model.generation_config\n",
    "generation_config.max_length = 8\n",
    "generation_config.num_beams = 1\n",
    "\n",
    "outputs = model.generate(input_ids, generation_config=generation_config)\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
